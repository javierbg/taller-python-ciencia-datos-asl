{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este breve tutorial explica alguna de las herramientas básicas de Ciencia de Datos disponibles en Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Qué es Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python es un lenguaje de programación interpretado.\n",
    "- Su nombre proviene de la afición de su creador original, [Guido van Rossum](https://es.wikipedia.org/wiki/Guido_van_Rossum), por los humoristas británicos [Monty Python](https://es.wikipedia.org/wiki/Monty_Python).\n",
    "- Características:\n",
    "  - Programación orientada a objetos\n",
    "  - Programación imperativa\n",
    "  - Programación funcional.\n",
    "  - Es multiplataforma y posee una licencia abierta.\n",
    "\n",
    "Para una introducción a Python, consulta el [taller de Python impartido en el ASL](https://aulasoftwarelibre.github.io/taller-de-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entornos de desarrollo para Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Entornos de desarrollo para Python\n",
    "  - [PyCharm](https://www.jetbrains.com/pycharm/)\n",
    "  - [Spyder](https://github.com/spyder-ide/spyder)\n",
    "  - [Visual Studio Code](https://code.visualstudio.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter Notebooks (libros de notas o cuadernos Jupyter)\n",
    "==================\n",
    "\n",
    "* Puedes ejecutar un `Cell` (celda) pulsando ``[shift] + [Enter]`` o presionando el botón `Play` en la barra de herramientas.\n",
    "\n",
    "![](images/ipython_run_cell.png)\n",
    "\n",
    "* Puedes obtener ayuda sobre una función u objeto presionando ``[shift] + [tab]`` después de los paréntesis de apertura ``function(``\n",
    "\n",
    "![](images/ipython_help-1.png)\n",
    "\n",
    "* También puedes obtener la ayuda ejecutando ``function?``\n",
    "\n",
    "![](images/ipython_help-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [NumPy](https://numpy.org/)\n",
    "\n",
    "Librería de cálculo numérico para Python.\n",
    "- Escrita en C: operaciones muy rápidas\n",
    "- Permite trabajar con arrays n-dimensionales (vectores, matrices, etc.)\n",
    "- Contiene un amplio catálogo de operaciones numércias: creación de matrices, operaciones vectoriales, *slicing*, cálculo matricial, polinomios, tratamiento de señales...\n",
    "\n",
    "**Todas** las librerías de cálculo científico del ecosistema de Python se basan en NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [`pandas`](https://pandas.pydata.org/)\n",
    "\n",
    "Herramienta de análisis de datos muy flexible construída sobre NumPy.\n",
    "\n",
    "Nos permite trabajar sobre \"DataFrames\" (datos tabulados) con indices de tipo arbitrario (pueden ser numéricos, etiquetas, fechas...)\n",
    "\n",
    "<img src=\"images/table_dataframe.svg\" width=\"40%\">\n",
    "\n",
    "Incluye herramientas para cargar/guardar datos en distintos formatos (CSV, Calc/Excel, JSON...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos\n",
    "\n",
    "El método `read_csv()` de `pandas` permite dos modos de trabajo: que el propio fichero CSV tenga una fila con los nombres de las variables o que nosotros especifiquemos los nombres de las variables en la llamada. En este caso, vamos a utilizar la segunda aproximación. De esta forma, creamos un array con los nombres de las variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "nombre_variables = ['longitud_sepalo', 'ancho_sepalo', 'longitud_petalo', 'ancho_petalo', 'clase']\n",
    "# Carga de datos desde la web: descarga el CSV y lo carga como DataFrame\n",
    "iris = pd.read_csv('https://raw.githubusercontent.com/ayrna/tutorial-scikit-learn-IMC/master/data/iris.csv',\n",
    "                   names = nombre_variables)\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se trata del dataset [\"iris\"](https://es.wikipedia.org/wiki/Conjunto_de_datos_flor_iris), un ejemplo típico en *machine learning*.  En esta base de datos hay tres clases a predecir, que son tres especies distintas del género *Iris*, de manera que, para cada flor, se extraen cuatro medidas o variables de entrada (longitud y ancho de los pétalos y los sépalos, en cm). Las tres especies a distinguir son *Iris setosa*, *Iris virginica* e *Iris versicolor*.\n",
    "\n",
    "Este dataset fue obtenido por el botanista Edgar Anderson y utilizado y popularizado por el biólogo y estadista Ronald Fisher en su artículo de 1936 \"*The use of multiple measurements in taxonomic problems*\" (\"El uso de varias mediciones en problemas de taxonomía\").\n",
    "\n",
    "<figure>\n",
    "<img src=\"images/iris-machinelearning.png\" width=\"60%\">\n",
    "    <figcaption>Imagen extraída de <a href=\"https://www.datacamp.com/community/tutorials/machine-learning-in-r\">Machine Learning in R for beginners</a></figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspección de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de nada, es conveniente realizar una pequeña **inspección** de los datos. Si simplemente queremos ver la cabecera del dataset, podemos utilizar el método `head(n)`, que devuelve un DataFrame incluyendo los primeros `n` patrones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manejo de objetos `DataFrame` y matrices numpy (`ndarray`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los [`DataFrame`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) son objetos que representan a los *datasets* con los que vamos a operar. Permiten realizar muchas operaciones de forma automática, ayudando a transformar las variables de forma muy cómoda. Internamente, el dataset se guarda en un array bidimensional de `numpy` (clase [`ndarray`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` nos da la ventaja de poder utilizar las etiquetas de fila (`index`) y columna (`column`) para seleccionarlas de forma más explícita.\n",
    "\n",
    "Esto además permite **mezclar tipos de datos** (los array de NumPy deben ser homogéneos) en caso de que lo necesitemos.\n",
    "\n",
    "Para extraer columnas específicas podemos usar los corchetes `[]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['ancho_sepalo'] # Las columnas son objetos de tipo \"Series\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[['ancho_sepalo', 'longitud_sepalo']] # Podemos extraer varias columnas a la vez\n",
    "                                          # en formato DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para seleccionar filas y columnas específicas de de un [`DataFrame`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) especificando sus etiquetas, utilizamos la propiedad `loc` de la siguiente manera:\n",
    "- `df.loc[i,j]`: accede al valor de la fila con etiqueta `i` y columna con etiqueta `j`.\n",
    "- `df.loc[[a, b, c], :]`: devuelve otro `DataFrame` sólo con las filas `a`, `b` y `c`.\n",
    "- `df.loc[:, [d, e, f]]`: ídem, pero para las columnas.\n",
    "- `df.loc[[a, b, c], [d, e, f]]`: podemos combinar filas y columnas.\n",
    "\n",
    "Si, en cambio, queremos utilizar índices enteros lo haríamos usando la propiedad `iloc` de la siguiente manera:\n",
    "- `df.iloc[i,j]`: accede al valor de la fila `i` columna `j`.\n",
    "- `df.iloc[i:j,k]`: devuelve otro `DataFrame` con la subtabla correspondiente a las filas desde la `i` hasta la `j-1` y a la columna `k`.\n",
    "- `df.iloc[i:j,k:l]`: devuelve otro `DataFrame` con la submatriz correspondiente a las filas desde la `i` hasta la `j-1` y a las columnas desde la `k` hasta la `l-1`.\n",
    "- `df.iloc[i:j,:]`: devuelve otro `DataFrame` con la submatriz correspondiente a las filas desde la `i` hasta la `j-1` y **todas** las columnas.\n",
    "- `df.iloc[:,i:j]`: devuelve otro `DataFrame` con la submatriz correspondiente a **todas** las filas y a las columnas desde la `k` hasta la `l`.\n",
    "\n",
    "De esta forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.loc[7, 'ancho_petalo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto seleccionará las filas cuya etiqueta es 1, 10 y 20\n",
    "# y las columnas cuya etiqueta es 'ancho_petalo', 'longitud_sepalo' o 'clase'\n",
    "iris.loc[[1, 10, 20], ['ancho_petalo', 'longitud_sepalo', 'clase']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.iloc[10:20, 3:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El acceso a los elementos de un [`DataFrame`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) con `iloc` es similar a obtener su [`ndarray`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html) de NumPy subyacente, con la desventaja de no poder trabajar con datos mixtos (números y cadenas, por ejemplo). Para lo cual simplemente tenemos que utilizar el atributo `values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La sintaxis de indexación en un [`ndarray`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html) es la siguiente:\n",
    "- `array[i,j]`: accede al valor de la fila `i` columna `j`.\n",
    "- `array[i:j,k]`: devuelve otro `ndarray` con la submatriz correspondiente a las filas desde la `i` hasta la `j-1` y a la columna `k`.\n",
    "- `array[i:j,k:l]`: devuelve otro `ndarray` con la submatriz correspondiente a las filas desde la `i` hasta la `j-1` y a las columnas desde la `k` hasta la `l`.\n",
    "- `array[i:j,:]`: devuelve otro `ndarray` con la submatriz correspondiente a las filas desde la `i` hasta la `j-1` y **todas** las columnas.\n",
    "- `array[:,i:j]`: devuelve otro `ndarray` con la submatriz correspondiente a **todas** las filas y a las columnas desde la `k` hasta la `l`.\n",
    "De esta forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_array = iris.values\n",
    "print(iris_array[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar el array es menos bonito\n",
    "iris_array[0:2,2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_array[1:6,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el acceso a través del `ndarray` es, por lo general, más cómodo, ya que no requerimos del nombre de las variables, aunque es menos explícito. Ahora vamos a manejar una matriz de valores aleatorios, para ver algunas características adicionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Semilla de números aleatorios (para reproducibilidad)\n",
    "rnd = np.random.RandomState(seed=123)\n",
    "\n",
    "# Generar una matriz aleatoria\n",
    "X = rnd.uniform(low=0.0, high=1.0, size=(3, 5))  # dimensiones 3x5\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder a los elementos\n",
    "\n",
    "# Obtener un único elemento\n",
    "# (primera fila, primera columna)\n",
    "print(X[0, 0])\n",
    "\n",
    "# Obtener una fila\n",
    "# (segunda fila)\n",
    "print(X[1])\n",
    "\n",
    "# Obtener una columna\n",
    "# (segunda columna)\n",
    "print(X[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{bmatrix}\n",
    "    1 & 2 & 3 & 4 \\\\\n",
    "    5 & 6 & 7 & 8\n",
    "\\end{bmatrix}^T\n",
    "= \n",
    "\\begin{bmatrix}\n",
    "    1 & 5 \\\\\n",
    "    2 & 6 \\\\\n",
    "    3 & 7 \\\\\n",
    "    4 & 8\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la traspuesta\n",
    "print(X)\n",
    "print(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un vector de números con la misma separación\n",
    "# sobre un intervalo prefijado\n",
    "y = np.linspace(start=0, stop=12, num=5)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar el vector en un vector fila\n",
    "print(y[np.newaxis, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar el vector en un vector columna\n",
    "print(y[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Indexar según un conjunto de números enteros\n",
    "indices = np.array([3, 1, 0])\n",
    "print(indices)\n",
    "X[:, indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorización de operaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando usamos NumPy en Python, al igual que en otros lenguajes de programación como R o Matlab, debemos intentar, siempre que sea posible, *vectorizar* las operaciones. Esto es utilizar operaciones matriciales en lugar de bucles que recorran los arrays. La razón es que este tipo de operaciones están muchos más optimizadas y que el proceso de referenciación de *arrays* puede consumir mucho tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imaginemos que queremos imprimir el área de sépalo de todas las flores. Compara la diferencia entre hacerlo mediante un bucle `for` y mediante operaciones matriciales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar un array con el área del sépalo (longitud*anchura), utilizando un for:\n",
    "\n",
    "# Crear un array vacío\n",
    "areaSepaloArray = np.empty(iris_array.shape[0], dtype=np.float32)\n",
    "\n",
    "# Bucle for \n",
    "for i in range(iris_array.shape[0]):\n",
    "    areaSepaloArray[i] = iris_array[i,0] * iris_array[i,1]\n",
    "    \n",
    "print(areaSepaloArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar un array con el área del sépalo (longitud*anchura), utilizando operaciones matriciales\n",
    "areaSepaloArray_2 = iris_array[:,0] * iris_array[:,1]\n",
    "areaSepaloArray_2 = areaSepaloArray_2.astype(np.float32)\n",
    "print(areaSepaloArray_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.arange(25).reshape((5, 5))\n",
    "a2 = np.arange(25, 50).reshape((5, 5))\n",
    "\n",
    "print(a1)\n",
    "print(a2)\n",
    "a1 + a2 # Suma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a1 * a2 # Producto elemento a elemento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1.sum() # Suma de todos los elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a2.sum(axis=0) # Suma de todas las filas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es más, los `ndarray` permiten aplicar operaciones lógicas, que devuelven otro `ndarray` con el resultado de realizar esas operaciones lógicas:\n",
    "¿Qué patrones tienen la longitud del pétalo (variable 2) mayor a 5 unidades?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_array[:,2] > 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A su vez, este `ndarray` se puede usar para indexar el `ndarray` original:\n",
    "¿cuál es la clase de los patrones que tienen la longitud del pétalo mayor que 5 unidades?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_array[iris_array[:,2] > 5,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagina que ahora queremos imprimir la longitud de sépalo de aquellas flores cuya longitud de sépalo es mayor que 2. Compara la versión con `for` y la versión \"vectorizada\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir las longitudes de sépalo mayores que 3, utilizando un for\n",
    "iris_array = iris.values\n",
    "for i in range(iris_array.shape[0]):\n",
    "    valorSepalo = iris_array[i,0]\n",
    "    if valorSepalo > 5:\n",
    "        print(valorSepalo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir las longitudes de sépalo mayores que 2, utilizando operaciones matriciales\n",
    "print(iris_array[iris_array[:,0] > 5, 0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar algunas funciones adicionales sobre objetos de tipo `ndarray`. Por ejemplo, las funciones [`numpy.mean`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html) y [`numpy.std`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.std.html) nos sirven para calcular la media y la desviación típica, respectivamente, de los valores contenidos en el `ndarray` que se pasa como argumento.\n",
    "\n",
    "Por último, podemos realizar operaciones matriciales con los `ndarray` de forma muy simple y optimizada. La función [`numpy.dot`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html) multiplica dos `ndarray`, siempre que sus dimensiones sean compatibles. La función [`numpy.transpose`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.transpose.html) nos devuelve la traspuesta de la matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1, 0], [0, 1]]\n",
    "b = [[4, 1], [2, 2]]\n",
    "\n",
    "np.dot(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**: Prueba a imprimir la media y la desviación típica del área de sépalo aquellas flores que son de tipo *virginica*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Matplotlib](https://matplotlib.org/)\n",
    "Una parte muy importante del aprendizaje automático es la visualización de datos. La herramienta más habitual para esto en Python es Matplotlib. Es un paquete extremadamente flexible y ahora veremos algunos elementos básicos.\n",
    "\n",
    "Ya que estamos usando los libros (*notebooks*) Jupyter, vamos a usar una de las [funciones mágicas](https://ipython.org/ipython-doc/3/interactive/magics.html) que vienen incluidas en IPython: el modo \"*matoplotlib inline*\", que dibujará los *plots* directamente en el cuaderno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dibujar una línea\n",
    "x = np.linspace(0, 10, 100)\n",
    "plt.plot(x, np.sin(x)); # El ; evita que aparezca en la salida de la celda el objeto \"plot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dibujar un scatter (dispersión)\n",
    "x = np.random.normal(size=500)\n",
    "y = np.random.normal(size=500)\n",
    "plt.scatter(x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar imágenes usando imshow\n",
    "# - Tener en cuenta que el origen por defecto está arriba a la izquierda\n",
    "\n",
    "x = np.linspace(0, 4*np.pi, 100).reshape((1, 100))\n",
    "y = np.linspace(0, 4*np.pi, 100).reshape((100, 1))\n",
    "im = y * np.sin(x) * np.cos(y)\n",
    "print(im.shape)\n",
    "\n",
    "plt.imshow(im);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Esta imagen no es más que [una proyección de la función y * sen(x) * cos(y)](https://www.google.es/search?q=y*sin%28x%29*cos%28y%29+from+-6+to+6&dcr=0&ei=rraXYJWIJIymaKDqs6AO&oq=y*sin%28x%29*cos%28y%29+from+-6+to+6&gs_lcp=Cgdnd3Mtd2l6EANQj1JYnFRgoFdoAXAAeACAAVKIAecBkgEBM5gBAKABAaoBB2d3cy13aXrAAQE&sclient=gws-wiz&ved=0ahUKEwiVl4a6r7zwAhUMExoKHSD1DOQQ4dUDCA0&uact=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer un diagrama de curvas de nivel (contour plot)\n",
    "# - El origen aquí está abajo a la izquierda\n",
    "plt.contour(im);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El modo \"widget\" en lugar de inline permite que los plots sean interactivos\n",
    "%matplotlib widget\n",
    "# Plot en 3D\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "ax = plt.axes(projection='3d')\n",
    "xgrid, ygrid = np.meshgrid(x[0,:], y[:,0])\n",
    "ax.plot_surface(xgrid, ygrid, im, cmap=plt.cm.viridis, cstride=2, rstride=2, linewidth=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay muchísimos tipos de gráficos disponibles. Una forma útila de explorarlos es mirar la [galería de matplotlib](https://matplotlib.org/stable/gallery/index.html).\n",
    "\n",
    "Prueba alguno de estos ejemplos. Por ejemplo, [`path_patch_demo.py`](https://matplotlib.org/mpl_examples/shapes_and_collections/path_patch_demo.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Demo of a PathPatch object.\n",
    "\"\"\"\n",
    "import matplotlib.path as mpath\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "Path = mpath.Path\n",
    "path_data = [\n",
    "    (Path.MOVETO, (1.58, -2.57)),\n",
    "    (Path.CURVE4, (0.35, -1.1)),\n",
    "    (Path.CURVE4, (-1.75, 2.0)),\n",
    "    (Path.CURVE4, (0.375, 2.0)),\n",
    "    (Path.LINETO, (0.85, 1.15)),\n",
    "    (Path.CURVE4, (2.2, 3.2)),\n",
    "    (Path.CURVE4, (3, 0.05)),\n",
    "    (Path.CURVE4, (2.0, -0.5)),\n",
    "    (Path.CLOSEPOLY, (1.58, -2.57)),\n",
    "    ]\n",
    "codes, verts = zip(*path_data)\n",
    "path = mpath.Path(verts, codes)\n",
    "patch = mpatches.PathPatch(path, facecolor='r', alpha=0.5)\n",
    "ax.add_patch(patch)\n",
    "\n",
    "# plot control points and connecting lines\n",
    "x, y = zip(*path.vertices)\n",
    "line, = ax.plot(x, y, 'go-')\n",
    "\n",
    "ax.grid()\n",
    "ax.axis('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a utilizar lo que hemos aprendido para visualizar el dataset `iris`. Vamos a extraer los nombres de las clases y asignarles un color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colors = ['blue', 'red', 'green'] # Color para cada clase\n",
    "iris_target_names = np.unique(iris['clase'])\n",
    "iris_target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "variable = 'longitud_petalo'\n",
    "\n",
    "for nombre, color in zip(iris_target_names, colors): #¿qué hace zip?\n",
    "    #Separamos el conjunto en las distintas clases\n",
    "    patrones = (iris['clase'] == nombre)\n",
    "    plt.hist(iris.loc[patrones, variable], label=nombre, color=color)\n",
    "\n",
    "plt.xlabel(variable)\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuerda que las variables de entrada eran *['longitud_sepalo', 'ancho_sepalo', 'longitud_petalo', 'ancho_petalo', 'clase']*, sabiendo esto, ¿qué debemos modificar  en el código superior para mostrar la longitud del sépalo? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vamos a representar en un gráfico la relación entre dos variables de entrada, así podremos ver si los patrones tienen algunas características que nos ayuden a crear un modelo lineal. Prueba distintas combinaciones de variables que se representan en los ejes, para ello modifica los valores de *vairable_x* y *variable_y*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_x = 'ancho_sepalo'\n",
    "variable_y = 'longitud_sepalo'\n",
    "\n",
    "for nombre, color in zip(iris_target_names, colors):\n",
    "    patrones = (iris['clase'] == nombre)\n",
    "    plt.scatter(iris.loc[patrones, variable_x], \n",
    "                iris.loc[patrones, variable_y],\n",
    "                label=nombre, c=color)\n",
    "\n",
    "plt.xlabel(variable_x)\n",
    "plt.ylabel(variable_y)\n",
    "plt.legend(loc='upper left');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Has encontrado alguna combinación que haga que los datos sean linealmente separables?\n",
    "Es un poco tedioso probar todas las posibles combinaciones, ¡y eso que en este ejemplo tenemos pocas variables!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrices scatterplot\n",
    "\n",
    "En lugar de realizar los plots por separado, una herramienta común que utilizan los analistas son las **matrices scatterplot**.\n",
    "\n",
    "Estas matrices muestran los scatter plots entre todas las características del dataset, así como los histogramas para ver la distribución de cada característica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "clases_numeros, clases_nombres = pd.factorize(iris['clase'])\n",
    "clases_numeros, clases_nombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(iris, c=clases_numeros, figsize=(8, 8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [`scikit-learn`](https://scikit-learn.org/stable/modules/classes.html)\n",
    "- Librería que proporciona un amplio conjunto de algoritmos de aprendizaje supervisado y no supervisado a través de una consistente interfaz en Python.\n",
    "- Publicado bajo licencia BSD y distribuido en muchos sistemas Linux, favorece el uso comercial y educacional.\n",
    "- Esta librería se ha construido sobre [`SciPy`](http://www.scipy.org/) (*Scientific Python*), la cual ofrece funcionalidad adicional sobre NumPy (algoritmos de grafos, árboles, distancias...)\n",
    "- Se centra en el modelado de datos y no en cargar y manipular los datos, para lo que utilizaríamos NumPy y `pandas`. Algunas cosas que podemos hacer con `scikit-learn` son:\n",
    "  - Agrupamiento (*clustering*)\n",
    "  - Validación cruzada\n",
    "  - *Datasets* de prueba\n",
    "  - Reducción de la dimensionalidad\n",
    "  - Métodos *ensemble*\n",
    "  - Selección de características (*feature selection*)\n",
    "  - Ajuste de parámetros (*parameter tuning*)\n",
    "- Las principales ventajas de `scikit-learn` son las siguientes:\n",
    "  - Interfaz consistente ante modelos de aprendizaje automático.\n",
    "  - Proporciona muchos parámetros de configuración.\n",
    "  - Documentación excepcional.\n",
    "  - Desarrollo muy activo.\n",
    "  - Comunidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División de datos en entrenamiento y test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque a veces nos proporcionan los datos ya divididos en los conjuntos de entrenamiento y test, conviene saber como podríamos realizar esta división. El siguiente código muestra una función que divide los datos de forma aleatoria, utilizando operaciones *vectorizadas*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividir_ent_test(dataframe, porcentaje=0.6):\n",
    "    \"\"\" \n",
    "    Función que divide un DataFrame aleatoriamente en entrenamiento y en test.\n",
    "    Recibe los siguientes argumentos:\n",
    "    - dataframe: DataFrame que vamos a utilizar para extraer los datos\n",
    "    - porcentaje: porcentaje de patrones en entrenamiento\n",
    "    Devuelve:\n",
    "    - train: DataFrame con los datos de entrenamiento\n",
    "    - test: DataFrame con los datos de test\n",
    "    \"\"\"\n",
    "    mascara = np.random.rand(len(dataframe)) < porcentaje\n",
    "    train = dataframe[mascara]\n",
    "    test = dataframe[~mascara] #¿para qué sirve ~?\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_train, iris_test = dividir_ent_test(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iris_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, podemos quedarnos con las columnas correspondientes a las variables de entrada (todas salvo la última) y la correspondiente a la variable de salida (en este caso, la última):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs_iris = iris_train.values[:,0:-1]\n",
    "train_outputs_iris = iris_train.values[:,-1]\n",
    "\n",
    "print(train_inputs_iris.shape)\n",
    "print(train_outputs_iris.shape)\n",
    "\n",
    "test_inputs_iris = iris_test.values[:,0:-1]\n",
    "test_outputs_iris = iris_test.values[:,-1]\n",
    "\n",
    "print(test_inputs_iris.shape)\n",
    "print(test_outputs_iris.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nos proporcionan la base de datos completa para que hagamos nosotros las particiones, todas las clases y funciones del módulo [`sklearn.model_selection`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection) de `scikit-learn` nos pueden facilitar mucho la labor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "inputs_iris = iris.values[:,0:-1]\n",
    "outputs_iris = iris.values[:,-1]\n",
    "\n",
    "train_inputs_iris, test_inputs_iris, train_outputs_iris, test_outputs_iris = \\\n",
    "       train_test_split(inputs_iris, outputs_iris, test_size=0.33, random_state=42, stratify=outputs_iris)\n",
    "\n",
    "print(train_inputs_iris.shape)\n",
    "print(test_inputs_iris.shape)\n",
    "print([sum(train_outputs_iris==etiqueta)/train_outputs_iris.shape[0] for etiqueta in np.unique(outputs_iris)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labores de preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, `scikit-learn` no acepta cadenas como parámetros de las funciones, todo deben de ser números. Para ello, nos podemos valer del objeto [`sklearn.preprocessing.LabelEncoder`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html), que nos transforma automáticamente las cadenas a números. La forma en que se utiliza es la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#Creación del método\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "#Entrenamiento del método\n",
    "label_encoder.fit(train_outputs_iris)\n",
    "print(label_encoder.classes_)\n",
    "\n",
    "#Obtención de salidas\n",
    "train_outputs_iris_encoded = label_encoder.transform(train_outputs_iris)\n",
    "test_outputs_iris_encoded = label_encoder.transform(test_outputs_iris)\n",
    "\n",
    "print(train_outputs_iris)\n",
    "print(train_outputs_iris_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podéis observar, primero se crea el `LabelEncoder` y luego se \"entrena\" mediante el método `fit`. Para un `LabelEncoder`, \"entrenar\" el modelo es decidir el mapeo que vimos anteriormente, en este caso:\n",
    "- `Iris-setosa` -> 0\n",
    "- `Iris-versicolor` -> 1\n",
    "- `Iris-virginica` -> 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez entrenado, utilizando el método `transform` del `LabelEncoder`, podremos transformar cualquier `ndarray` que queramos (hubiéramos tenido un error si alguna de las etiquetas de test no estuviera en train). Esta estructura (método `fit` más método `transform` o `predict`) se repite en muchos de los objetos de `scikit-learn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay muchas más tareas de preprocesamiento que se pueden hacer en `scikit-learn`. Consulta el paquete [`sklearn.preprocessing`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear y evaluar un clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, vamos a crear un modelo de clasificación y a obtener su matriz de confusión. Vamos a utilizar el clasificador [KNeighborsClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html), que clasifica cada patrón asignándole la clase mayoritaria según los `k` vecinos más cercanos al patrón a clasificar. Consulta siempre la documentación de cada objeto para ver los parámetros del algoritmo (en este caso, el parámetro decisivo es `n_neighbors`). Veamos como se realizaría el entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(train_inputs_iris, train_outputs_iris_encoded)\n",
    "print(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos el modelo entrenado. Este modelo es de tipo *lazy*, en el sentido de que no existen parámetros a ajustar durante el entrenamiento. Lo único que hacemos es acomodar las entradas en una serie de estructuras de datos que faciliten el cálculo de distancias a la hora de predecir la etiqueta de datos nuevos. Si ahora queremos predecir las etiquetas de test, podemos hacer uso del método `predict`, que aplica el modelo ya entrenado a datos nuevos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediccion_test = knn.predict(test_inputs_iris)\n",
    "print(prediccion_test)\n",
    "print(test_outputs_iris_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos saber cómo de buena ha sido la clasificación, todo modelo de clasificación o regresión en `scikit-learn` tiene un método `score` que nos devuelve la bondad del modelo con respecto a los valores esperados, a partir de las entradas suministradas. La medida por defecto utilizada en [KNeighborsClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) es el porcentaje de patrones bien clasificados (CCR o *accuracy*). La función se utiliza de la siguiente forma (internamente, esta función llama a `predict`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = knn.score(test_inputs_iris, test_outputs_iris_encoded)\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto sería similar a hacer la comparación a mano y calcular la media:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(prediccion_test == test_outputs_iris_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para imprimir la matriz de confusión de unas predicciones, podemos utilizar la función [`sklearn.metrics.confusion_matrix`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix), que nos va devolver la matriz ya formada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(test_outputs_iris_encoded, prediccion_test)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(knn, test_inputs_iris, test_outputs_iris_encoded)#, display_labels=label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurar los parámetros de un clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagina que quieres configurar el número de vecinos más cercanos (`n_neighbors`), de forma que la precisión en entrenamiento sea lo más alta posible. Lo podríamos hacer de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nn in range(1,15):\n",
    "    knn = KNeighborsClassifier(n_neighbors=nn)\n",
    "    knn.fit(train_inputs_iris, train_outputs_iris_encoded)\n",
    "    precisionTrain = knn.score(train_inputs_iris, train_outputs_iris_encoded)\n",
    "    precisionTest = knn.score(test_inputs_iris, test_outputs_iris_encoded)\n",
    "    print(\"%d vecinos: \\tCCR train = %.2f%%, \\tCCR test = %.2f%%\" % (nn, precisionTrain*100, precisionTest*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio propuesto para realizar\n",
    "\n",
    "La base de datos `german` contiene datos bancarios de crédito de distintos clientes de un banco. El problema que presenta consiste en predecir si se debe o no otorgar un crédito a un cliente específico (decisión binaria).\n",
    "\n",
    "Utiliza la base de datos `german` para entrenar dos modelos supervisados de clasificación:\n",
    "- Uno basado en los k vecinos más cercanos: [KNeighborsClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html).\n",
    "- Otro basado en un modelo lineal. Vamos a utilizar el modelo de regresión logística: [LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "\n",
    "La base de datos está disponible en la UCI, bajo el nombre [*Statlog (German Credit Data) Data Set*](https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29). Bájala y preprocésala para realizar el entrenamiento (utiliza la versión numérica, `german.data-numeric`, observa que los datos no tienen cabecera y utiliza el método `read_csv` de `pandas` especificando correctamente el separador, que en este caso es el uno o más espacios, es decir, `'\\s+'`). Divide los datos en 60% de entrenamiento y 40% de test (utiliza la función [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split)). Tienes que normalizar todas las variables de entrada para que queden en el intervalo `[0,1]` (consulta información sobre [MinMaxScaler](http://scikit-learn.org/stable/modules/preprocessing.html#scaling-features-to-a-range)). Intenta ajustar lo mejor posibles los parámetros de los clasificadores.\n",
    "\n",
    "*Corrección*: a fecha de 9/5/2021 el sitio de la UCI está caído, así que en caso de que siga siendo así, tienes el CSV con estos mismos datos en el fichero `resources/german.csv` de este mismo repositorio. En este caso el fichero  SÍ tiene cabeceras y el separador es una coma en lugar de espacios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencias\n",
    "Este tutorial se ha basado en gran parte en el siguiente material:\n",
    "- Python como alternativa a R en *machine learning*. Mario Pérez Esteso. [Enlace a Github](https://github.com/MarioPerezEsteso/Python-Machine-Learning). [Enlace a Youtube](https://www.youtube.com/watch?v=8yz4gWt7Klk). \n",
    "- Tutorial de Alex Gramfort y Andreas Mueller [[Github]](https://github.com/amueller/scipy-2017-sklearn)[[Youtube1]](https://www.youtube.com/watch?v=2kT6QOVSgSg)[[Youtube2]](https://www.youtube.com/watch?v=WLYzSas511I)\n",
    "\n",
    "Se recomiendan los siguientes tutoriales adicionales para aprender más sobre el manejo de la librería:\n",
    "- *An introduction to machine learning with scikit-learn*. Documentación oficial de `scikit-learn`. [http://scikit-learn.org/stable/tutorial/basic/tutorial.html](http://scikit-learn.org/stable/tutorial/basic/tutorial.html).\n",
    "- *A tutorial on statistical-learning for scientific data processing*. Documentación oficial de `scikit-learn`. [http://scikit-learn.org/stable/tutorial/statistical_inference/index.html](http://scikit-learn.org/stable/tutorial/statistical_inference/index.html).\n",
    "\n",
    "Por último, para aprender la sintaxis básica de Python en menos de 13 horas, se recomienda el siguiente curso de *CodeAcademy*:\n",
    "- Curso de Python de CodeAcademy. [https://www.codecademy.com/es/learn/python](https://www.codecademy.com/es/learn/python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
